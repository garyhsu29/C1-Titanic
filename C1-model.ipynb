{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('train.csv').drop(['Name','Cabin','PassengerId','Ticket'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('train.csv').drop(['Name','Cabin','PassengerId','Ticket'],axis=1)\n",
    "df_train = df_train.fillna({'Age':df_train['Age'].mean()}).dropna()\n",
    "X = df_train.drop('Survived',axis=1)\n",
    "y = df_train['Survived']\n",
    "X_transform = pd.get_dummies(X,columns=['Sex','Embarked'])\n",
    "#X_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'max_depth': 5} With best accuracy: 0.81214848144\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_transform, y, test_size=0.2, random_state=0)\n",
    "d_parameters = {'max_depth':[5,6,7,8,9,10]}\n",
    "D_tree = tree.DecisionTreeClassifier()\n",
    "gs_d_tree = GridSearchCV(D_tree,d_parameters,cv=5)\n",
    "gs_d_tree.fit(X_transform,y)\n",
    "print('Best parameter:',gs_d_tree.best_params_,'With best accuracy:',gs_d_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'C': 1, 'gamma': 5} With best accuracy: 0.82114735658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_transform)\n",
    "#y_scaled = scaler.transform(y)\n",
    "# kernel: 'precomputed'  not work\n",
    "svc_paremeters = {'C':[0.01,0.1,1,10,100],'gamma':[0.01,0.1,1,5,10]}\n",
    "svc_clf = SVC()\n",
    "gs_svc_clf = GridSearchCV(svc_clf,svc_paremeters,cv=5)\n",
    "gs_svc_clf.fit(X_scaled,y)\n",
    "print('Best parameter:',gs_svc_clf.best_params_,'With best accuracy:',gs_svc_clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'C': 0.5, 'penalty': 'l2'} With best accuracy: 0.789651293588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_transform)\n",
    "\n",
    "logistic_paras = {'penalty':['l1','l2'],'C':[0.00005,0.005,0.05,0.5,1]}\n",
    "logis_clf = LogisticRegression()\n",
    "gs_logis_clf = GridSearchCV(logis_clf,logistic_paras,cv=5)\n",
    "gs_logis_clf.fit(X_scaled,y)\n",
    "print('Best parameter:',gs_logis_clf.best_params_,'With best accuracy:',gs_logis_clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP without Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'learning_rate': 'adaptive'} With best accuracy: 0.790776152981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_paras = {'learning_rate':['constant','invscaling','adaptive']}\n",
    "mlp_cls = MLPClassifier()\n",
    "gs_mlp_cls = GridSearchCV(mlp_cls,mlp_paras,cv=5)\n",
    "gs_mlp_cls.fit(X_transform,y)\n",
    "print('Best parameter:',gs_mlp_cls.best_params_,'With best accuracy:',gs_mlp_cls.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'alpha': 0.001, 'learning_rate_init': 0.01, 'max_iter': 300} With best accuracy: 0.826771653543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_transform)\n",
    "mlp_paras = {'learning_rate_init':[0.05,0.01,0.005,0.001],'max_iter':[300,500],'alpha':[0.001,0.005,0.0005]}\n",
    "mlp_cls = MLPClassifier()\n",
    "gs_mlp_cls = GridSearchCV(mlp_cls,mlp_paras,cv=5)\n",
    "gs_mlp_cls.fit(X_scaled,y)\n",
    "print('Best parameter:',gs_mlp_cls.best_params_,'With best accuracy:',gs_mlp_cls.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting with {'learning_rate': 0.05, 'max_depth': 4}  have better prediction\n",
    "# raw version without feature engineering best accuracy: 0.839145106862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_csv('train.csv').drop(['Name','Cabin','PassengerId','Ticket'],axis=1)\n",
    "df_train = df_train.fillna({'Age':df_train['Age'].mean()}).dropna()\n",
    "X = df_train.drop('Survived',axis=1)\n",
    "y = df_train['Survived']\n",
    "X_transform = pd.get_dummies(X,columns=['Sex','Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Train data\n",
    "df_train = df_train.fillna({'Age':df_train['Age'].mean()}).dropna()\n",
    "X = df_train.drop('Survived',axis=1)\n",
    "y = df_train['Survived']\n",
    "X_transform = pd.get_dummies(X,columns=['Sex','Embarked'])\n",
    "\n",
    "\n",
    "#test data\n",
    "df_pred = pd.read_csv('test.csv')\n",
    "pred_id = df_pred['PassengerId']\n",
    "X_test = df_pred.drop(['Name','Cabin','Ticket','PassengerId'],axis=1).fillna({'Age':df_pred['Age'].mean(),'Fare':df_pred['Fare'].mean()})\n",
    "pred_transform = pd.get_dummies(X_test,columns=['Sex','Embarked'])\n",
    "gb_clf = GradientBoostingClassifier(learning_rate=0.05, max_depth= 4)\n",
    "gb_clf.fit(X_transform,y)\n",
    "y_pred = gb_clf.predict(pred_transform)\n",
    "resdf = pd.DataFrame(data = y_pred,index=pred_id,columns=['Survived'])\n",
    "#resdf\n",
    "resdf.to_csv('res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "full_data = [train, test]\n",
    "#used info could easy to figure out the null value, \n",
    "#Train : Age,Cabin,Embarked,  \n",
    "#Test : Age,Fare,Cabin  \n",
    "print (train.info(),test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 1: pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Survived\n",
      "Pclass          \n",
      "1       0.629630\n",
      "2       0.472826\n",
      "3       0.242363\n"
     ]
    }
   ],
   "source": [
    "print(train[['Pclass','Survived']].groupby('Pclass').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 2: sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Survived\n",
      "Sex             \n",
      "female  0.742038\n",
      "male    0.188908\n"
     ]
    }
   ],
   "source": [
    "print(train[['Sex','Survived']].groupby('Sex').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 3: SibSp + Parch = Family member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Survived\n",
      "FamilyMembers          \n",
      "1              0.303538\n",
      "2              0.552795\n",
      "3              0.578431\n",
      "4              0.724138\n",
      "5              0.200000\n",
      "6              0.136364\n",
      "7              0.333333\n",
      "8              0.000000\n",
      "11             0.000000\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['FamilyMembers'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "print(train[['FamilyMembers','Survived']].groupby('FamilyMembers').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 4: Family member = 1 -> travel alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Survived\n",
      "IsAlone          \n",
      "0        0.505650\n",
      "1        0.303538\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilyMembers']== 1,'IsAlone'] = 1\n",
    "print(train[['IsAlone','Survived']].groupby('IsAlone').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 5 : Embark (2 missing in train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Survived\n",
      "Embarked          \n",
      "C         0.553571\n",
      "Q         0.389610\n",
      "S         0.336957\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(value = dataset['Embarked'].mode())\n",
    "print(train[['Embarked','Survived']].groupby('Embarked').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 6: Fare (1 missing in test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Survived\n",
      "CatagoricalFare          \n",
      "(-0.001, 7.91]   0.197309\n",
      "(7.91, 14.454]   0.303571\n",
      "(14.454, 31.0]   0.454955\n",
      "(31.0, 512.329]  0.581081\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(value = train['Fare'].median())\n",
    "train['CatagoricalFare'] = pd.qcut(train['Fare'],4)\n",
    "print(train[['CatagoricalFare','Survived']].groupby('CatagoricalFare').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 7: Age (many missing value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the data have many missing value in a column,instead of using mean,median, it should use random to guess the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Survived\n",
      "CategoricalAge          \n",
      "(-0.08, 20.0]   0.423077\n",
      "(20.0, 40.0]    0.375479\n",
      "(40.0, 60.0]    0.381295\n",
      "(60.0, 80.0]    0.227273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       (20.0, 40.0]\n",
       "1       (20.0, 40.0]\n",
       "2       (20.0, 40.0]\n",
       "3       (20.0, 40.0]\n",
       "4       (20.0, 40.0]\n",
       "5      (-0.08, 20.0]\n",
       "6       (40.0, 60.0]\n",
       "7      (-0.08, 20.0]\n",
       "8       (20.0, 40.0]\n",
       "9      (-0.08, 20.0]\n",
       "10     (-0.08, 20.0]\n",
       "11      (40.0, 60.0]\n",
       "12     (-0.08, 20.0]\n",
       "13      (20.0, 40.0]\n",
       "14     (-0.08, 20.0]\n",
       "15      (40.0, 60.0]\n",
       "16     (-0.08, 20.0]\n",
       "17      (20.0, 40.0]\n",
       "18      (20.0, 40.0]\n",
       "19      (20.0, 40.0]\n",
       "20      (20.0, 40.0]\n",
       "21      (20.0, 40.0]\n",
       "22     (-0.08, 20.0]\n",
       "23      (20.0, 40.0]\n",
       "24     (-0.08, 20.0]\n",
       "25      (20.0, 40.0]\n",
       "26     (-0.08, 20.0]\n",
       "27     (-0.08, 20.0]\n",
       "28     (-0.08, 20.0]\n",
       "29      (20.0, 40.0]\n",
       "           ...      \n",
       "861     (20.0, 40.0]\n",
       "862     (40.0, 60.0]\n",
       "863     (20.0, 40.0]\n",
       "864     (20.0, 40.0]\n",
       "865     (40.0, 60.0]\n",
       "866     (20.0, 40.0]\n",
       "867     (20.0, 40.0]\n",
       "868     (20.0, 40.0]\n",
       "869    (-0.08, 20.0]\n",
       "870     (20.0, 40.0]\n",
       "871     (40.0, 60.0]\n",
       "872     (20.0, 40.0]\n",
       "873     (40.0, 60.0]\n",
       "874     (20.0, 40.0]\n",
       "875    (-0.08, 20.0]\n",
       "876    (-0.08, 20.0]\n",
       "877    (-0.08, 20.0]\n",
       "878     (20.0, 40.0]\n",
       "879     (40.0, 60.0]\n",
       "880     (20.0, 40.0]\n",
       "881     (20.0, 40.0]\n",
       "882     (20.0, 40.0]\n",
       "883     (20.0, 40.0]\n",
       "884     (20.0, 40.0]\n",
       "885     (20.0, 40.0]\n",
       "886     (20.0, 40.0]\n",
       "887    (-0.08, 20.0]\n",
       "888     (20.0, 40.0]\n",
       "889     (20.0, 40.0]\n",
       "890     (20.0, 40.0]\n",
       "Name: CategoricalAge, Length: 891, dtype: category\n",
       "Categories (4, interval[float64]): [(-0.08, 20.0] < (20.0, 40.0] < (40.0, 60.0] < (60.0, 80.0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    age_ave = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    \n",
    "    random_age = np.random.randint(age_ave - age_std,age_ave + age_std, age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = random_age\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "train['CategoricalAge'] = pd.cut(train['Age'],4)\n",
    "print(train[['CategoricalAge','Survived']].groupby(['CategoricalAge']).mean())\n",
    "train['CategoricalAge'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 8: Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Survived\n",
       "Cabin          \n",
       "0      0.299854\n",
       "1      0.666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cabin'].fillna(0,inplace=True)\n",
    "train.loc[train['Cabin']!=0,'Cabin'] = 1\n",
    "train[['Cabin','Survived']].groupby('Cabin').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 9: Title (use re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "full_data = [train, test]\n",
    "#used info could easy to figure out the null value, \n",
    "#Train : Age,Cabin,Embarked,  \n",
    "#Test : Age,Fare,Cabin  \n",
    "print (train.info(),test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Mlle          2\n",
      "Major         2\n",
      "Ms            1\n",
      "Lady          1\n",
      "Jonkheer      1\n",
      "Capt          1\n",
      "Countess      1\n",
      "Mme           1\n",
      "Don           1\n",
      "Sir           1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_title(name):\n",
    "    match = re.search('([A-Za-z]+)\\.',name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return ''\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    \n",
    "print(train['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Miss  0.704301\n",
      "2      Mr  0.156673\n",
      "3     Mrs  0.793651\n",
      "4    Rare  0.318182\n"
     ]
    }
   ],
   "source": [
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Lady', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "print (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After the feature engineering, use the helpful feature the clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "full_data = [train, test]\n",
    "#used info could easy to figure out the null value, \n",
    "#Train : Age,Cabin,Embarked,  \n",
    "#Test : Age,Fare,Cabin  \n",
    "print (train.info(),test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare:\n",
    "(-0.001, 7.91]   0.197309\n",
    "(7.91, 14.454]   0.303571\n",
    "(14.454, 31.0]   0.454955\n",
    "(31.0, 512.329]  0.581081\n",
    "\n",
    "Age\n",
    "(-0.08, 16.0]   0.531532\n",
    "(16.0, 32.0]    0.343182\n",
    "(32.0, 48.0]    0.388462\n",
    "(48.0, 64.0]    0.434783\n",
    "(64.0, 80.0]    0.090909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    match = re.search('([A-Za-z]+)\\.',name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "output_index = test['PassengerId']\n",
    "full_data = [train,test]\n",
    "#Sex Embarked\n",
    "def clean_data(dataset):\n",
    "    dataset = pd.get_dummies(dataset,columns=['Sex','Embarked'])\n",
    "    dataset['Cabin'].fillna(0,inplace=True)\n",
    "    dataset.loc[dataset['Cabin']!=0,'Cabin'] = 1\n",
    "\n",
    "    #Fare\n",
    "    dataset.loc[dataset['Fare']<=7.91,'Fare']=0\n",
    "    dataset.loc[(dataset['Fare']>7.91)&(dataset['Fare']<=14.454),'Fare']=1\n",
    "    dataset.loc[(dataset['Fare']>14.454)&(dataset['Fare']<=31.0),'Fare']=2\n",
    "    dataset.loc[(dataset['Fare']>31.0)&(dataset['Fare']<=512.329),'Fare']=3\n",
    "    #Age\n",
    "    age_ave = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    random_age = np.random.randint(age_ave - age_std,age_ave + age_std, age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = random_age\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset.loc[dataset['Age']<=16.0,'Age']=0\n",
    "    dataset.loc[(dataset['Age']>16.0)&(dataset['Age']<=32.0),'Age']=1\n",
    "    dataset.loc[(dataset['Age']>32.0)&(dataset['Age']<=48.0),'Age']=2\n",
    "    dataset.loc[(dataset['Age']>48.0)&(dataset['Age']<=64.0),'Age']=3\n",
    "    dataset.loc[(dataset['Age']>64.0)&(dataset['Age']<=80.0),'Age']=4\n",
    "    # is Alone\n",
    "    dataset['FamilyMembers'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilyMembers']== 1,'IsAlone'] = 1\n",
    "\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    dataset['Title'] = dataset['Title'].replace(['Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Lady', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    drop_elements = ['PassengerId', 'Name', 'Ticket', 'SibSp','Parch', 'FamilyMembers']\n",
    "    dataset = dataset.drop(drop_elements,axis=1)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "clean_train = clean_data(train)\n",
    "train_label = clean_train['Survived']\n",
    "clean_train_without_label = clean_train.drop('Survived',axis=1)\n",
    "clean_test = clean_data(test)\n",
    "clean_test['Fare'].fillna(value=clean_test['Fare'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'learning_rate': 0.1, 'max_depth': 3} With best accuracy: 0.818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gb_paras = {'learning_rate':[0.5,0.1,0.05,0.01,0.005],'max_depth':[3,4,5,6]}\n",
    "gb_cls = GradientBoostingClassifier()\n",
    "gs_gb_cls = GridSearchCV(gb_cls,gb_paras,cv=5)\n",
    "gs_gb_cls.fit(clean_train_without_label,train_label)\n",
    "print('Best parameter:',gs_gb_cls.best_params_,'With best accuracy:',gs_gb_cls.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cls_bs = GradientBoostingClassifier(learning_rate=0.1,max_depth=4)\n",
    "gb_cls_bs.fit(clean_train_without_label,train_label)\n",
    "predict_res = gb_cls_bs.predict(clean_test)\n",
    "resdf = pd.DataFrame(data = predict_res,index=output_index,columns=['Survived'])\n",
    "#resdf\n",
    "resdf.to_csv('res_after_feature_engineering.csv')\n",
    "importance_list = list(zip(clean_train_without_label.columns , gb_cls_bs.feature_importances_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Fare', 0.24282314607763511),\n",
       " ('Title', 0.18574082231769015),\n",
       " ('Age', 0.16013124002757376),\n",
       " ('Pclass', 0.10224570882957482),\n",
       " ('Embarked_Q', 0.077510348176355728),\n",
       " ('IsAlone', 0.072630652507271465),\n",
       " ('Cabin', 0.055918002593549232),\n",
       " ('Embarked_C', 0.045636528110275895),\n",
       " ('Embarked_S', 0.028899167178304229),\n",
       " ('Sex_female', 0.017469734119310174),\n",
       " ('Sex_male', 0.010994650062459361)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(importance_list,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
